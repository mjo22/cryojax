{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jax and Equinox imports\n",
    "from functools import partial\n",
    "from typing import Tuple\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import Array, Float, PRNGKeyArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting imports and functions\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "def plot_image(image, fig, ax, cmap=\"gray\", label=None, **kwargs):\n",
    "    im = ax.imshow(image, cmap=cmap, origin=\"lower\", **kwargs)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    if label is not None:\n",
    "        ax.set(title=label)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/Documents/PhD/Research/cryojax_project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# CryoJAX imports\n",
    "\n",
    "import cryojax.image.transform as tf\n",
    "import cryojax.simulator as cxs\n",
    "from cryojax.data import (\n",
    "    RelionParticleParameterFile,\n",
    "    RelionParticleStackDataset,\n",
    "    simulate_particle_stack,\n",
    ")\n",
    "from cryojax.io import read_atoms_from_pdb\n",
    "from cryojax.rotations import SO3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Ensembles and doing Ensemble Reweighting\n",
    "\n",
    "In this tutorial we will generate a heterogeneous dataset by defining a distribution on multiple atomic structures. We will then compute a likelihood matrix\n",
    "$$ P_{nm} = p(y_n | x_m) $$\n",
    "\n",
    "where $y_n$ is a data point and $x_m$ is a structure in the ensemble. We will define the likelihood through one of cryoJAX's distributions, although in principle any distribution works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a starfile\n",
    "\n",
    "First, we will just follow the tutorial `simulate-relion-dataset.ipynb` to generate a starfile. No ensemble stuff yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(eqx.filter_vmap, in_axes=(0, None))\n",
    "def make_particle_parameters(\n",
    "    key: PRNGKeyArray, instrument_config: cxs.InstrumentConfig\n",
    "):  # -> tuple[RelionParticleParameters, RelionParticleParameters]:\n",
    "    # Generate random parameters\n",
    "\n",
    "    # Pose\n",
    "    # ... instantiate rotations\n",
    "    key, subkey = jax.random.split(key)  # split the key to use for the next random number\n",
    "    rotation = SO3.sample_uniform(subkey)\n",
    "\n",
    "    # ... now in-plane translation\n",
    "    ny, nx = instrument_config.shape\n",
    "\n",
    "    key, subkey = jax.random.split(key)  # do this everytime you use a key!!\n",
    "    offset_in_angstroms = (\n",
    "        jax.random.uniform(subkey, (2,), minval=-0.2, maxval=0.2)\n",
    "        * jnp.asarray((nx, ny))\n",
    "        * instrument_config.pixel_size\n",
    "    )\n",
    "    # ... build the pose\n",
    "    pose = cxs.EulerAnglePose.from_rotation_and_translation(rotation, offset_in_angstroms)\n",
    "\n",
    "    # CTF Parameters\n",
    "    # ... defocus\n",
    "    key, subkey = jax.random.split(key)\n",
    "    defocus_in_angstroms = jax.random.uniform(subkey, (), minval=10000, maxval=15000)\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    astigmatism_in_angstroms = jax.random.uniform(subkey, (), minval=0, maxval=100)\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    astigmatism_angle = jax.random.uniform(subkey, (), minval=0, maxval=jnp.pi)\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    phase_shift = jax.random.uniform(subkey, (), minval=0, maxval=0)\n",
    "    # no more random numbers needed\n",
    "\n",
    "    # now generate your non-random values\n",
    "    spherical_aberration_in_mm = 2.7\n",
    "    amplitude_contrast_ratio = 0.1\n",
    "\n",
    "    # ... build the CTF\n",
    "    transfer_theory = cxs.ContrastTransferTheory(\n",
    "        ctf=cxs.CTF(\n",
    "            defocus_in_angstroms=defocus_in_angstroms,\n",
    "            astigmatism_in_angstroms=astigmatism_in_angstroms,\n",
    "            astigmatism_angle=astigmatism_angle,\n",
    "            spherical_aberration_in_mm=spherical_aberration_in_mm,\n",
    "        ),\n",
    "        amplitude_contrast_ratio=amplitude_contrast_ratio,\n",
    "        phase_shift=phase_shift,\n",
    "    )\n",
    "\n",
    "    particle_parameters = {\n",
    "        \"instrument_config\": instrument_config,\n",
    "        \"pose\": pose,\n",
    "        \"transfer_theory\": transfer_theory,\n",
    "        \"metadata\": {},\n",
    "    }\n",
    "\n",
    "    return particle_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate instrument config\n",
    "instrument_config = cxs.InstrumentConfig(\n",
    "    shape=(128, 128),\n",
    "    pixel_size=1.5,\n",
    "    voltage_in_kilovolts=300.0,\n",
    "    pad_scale=1.0,  # no padding\n",
    ")\n",
    "\n",
    "# Generate RNG keys\n",
    "number_of_images = 100\n",
    "keys = jax.random.split(jax.random.key(0), number_of_images)\n",
    "\n",
    "# ... instantiate the RelionParticleDataset\n",
    "particle_parameters = make_particle_parameters(keys, instrument_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... generate the starfile\n",
    "new_parameters_file = RelionParticleParameterFile(\n",
    "    path_to_starfile=\"./outputs/heterogeneous_relion_dataset.star\",\n",
    "    mode=\"w\",  # writing mode!\n",
    "    exists_ok=True,  # in case the file already exists\n",
    ")\n",
    "new_parameters_file.append(particle_parameters)\n",
    "new_parameters_file.save(overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating images by choosing a random structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First load the starfile\n",
    "\n",
    "path_to_mrc_files = \"./outputs/relion_dataset_particles/heterogeneous\"\n",
    "\n",
    "particle_dataset = RelionParticleStackDataset(\n",
    "    new_parameters_file,\n",
    "    path_to_relion_project=path_to_mrc_files,\n",
    "    mode=\"w\",\n",
    "    mrcfile_settings={\"overwrite\": True},  # customize your .mrcs !\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryojax.constants import get_tabulated_scattering_factor_parameters\n",
    "\n",
    "\n",
    "filenames = [\"./data/groel_chainA.pdb\", \"./data/groel_chainA_holo.pdb\"]\n",
    "\n",
    "box_size = new_parameters_file[0][\"instrument_config\"].shape[0]\n",
    "\n",
    "potentials = []\n",
    "voxel_size = new_parameters_file[0][\"instrument_config\"].pixel_size\n",
    "for filename in filenames:\n",
    "    # Load the atomic structure and transform into a potential\n",
    "    atom_positions, atom_identities, bfactors = read_atoms_from_pdb(\n",
    "        filename, center=True, select=\"not element H\", loads_b_factors=True\n",
    "    )\n",
    "    scattering_factor_parameters = get_tabulated_scattering_factor_parameters(\n",
    "        atom_identities\n",
    "    )\n",
    "    atomic_potential = cxs.PengAtomicPotential(\n",
    "        atom_positions,\n",
    "        scattering_factor_a=scattering_factor_parameters[\"a\"],\n",
    "        scattering_factor_b=scattering_factor_parameters[\"b\"],\n",
    "        b_factors=bfactors,\n",
    "    )\n",
    "    # Convert to a real voxel grid\n",
    "    # This step is optional, you could use the atomic potential directly!\n",
    "    real_voxel_grid = atomic_potential.as_real_voxel_grid(\n",
    "        shape=(box_size, box_size, box_size), voxel_size=voxel_size\n",
    "    )\n",
    "    potential = cxs.FourierVoxelGridPotential.from_real_voxel_grid(\n",
    "        real_voxel_grid, voxel_size, pad_scale=2\n",
    "    )\n",
    "    potentials.append(potential)\n",
    "\n",
    "potentials = tuple(potentials)\n",
    "potential_integrator = cxs.FourierSliceExtraction()\n",
    "\n",
    "# Use this if using an atomic potential\n",
    "# potential_integrator = cxs.GaussianMixtureProjection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! info \n",
    "See our tutorial on simulating simple datasets for more details for how to generate an dataset with noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryojax.inference.distributions import IndependentGaussianPixels\n",
    "\n",
    "\n",
    "def compute_image(parameters, constant_args, per_particle_args):\n",
    "    potentials, potential_integrator, mask, snr = constant_args\n",
    "    noise_key, potential_id = per_particle_args  # jax random stuff\n",
    "\n",
    "    structural_ensemble = cxs.DiscreteStructuralEnsemble(\n",
    "        potentials,\n",
    "        parameters[\"pose\"],\n",
    "        cxs.DiscreteConformationalVariable(potential_id),\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble, potential_integrator, parameters[\"transfer_theory\"]\n",
    "    )\n",
    "\n",
    "    image_model = cxs.ContrastImageModel(\n",
    "        parameters[\"instrument_config\"], scattering_theory, mask=mask\n",
    "    )\n",
    "\n",
    "    distribution = IndependentGaussianPixels(\n",
    "        image_model,\n",
    "        variance=1.0,\n",
    "        signal_scale_factor=jnp.sqrt(snr),\n",
    "        normalizes_signal=True,\n",
    "    )\n",
    "\n",
    "    return distribution.sample(noise_key, applies_mask=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 0.1  # define whatever snr you want\n",
    "mask = tf.CircularCosineMask(\n",
    "    coordinate_grid=instrument_config.coordinate_grid_in_pixels,\n",
    "    radius=instrument_config.shape[0] // 2,\n",
    "    rolloff_width=0.0,\n",
    ")\n",
    "\n",
    "constant_args = (potentials, potential_integrator, mask, snr)\n",
    "\n",
    "# Generate RNG keys for per-image noise, and per-image conformations\n",
    "keys_noise = jax.random.split(jax.random.key(0), number_of_images)\n",
    "key_structure = jax.random.key(1)\n",
    "\n",
    "# Generate the per-image conformation assignments\n",
    "ensemble_weights = jnp.array([0.3, 0.7])  # weights for sampling structures\n",
    "potential_ids = jnp.ones((number_of_images,), dtype=int)\n",
    "\n",
    "# Exactly 30 will come from potential with id 0\n",
    "potential_ids = potential_ids.at[0 : int(ensemble_weights[0] * number_of_images)].set(0)\n",
    "\n",
    "simulate_particle_stack(\n",
    "    particle_dataset,\n",
    "    compute_image_fn=compute_image,\n",
    "    constant_args=constant_args,\n",
    "    per_particle_args=(keys_noise, potential_ids),\n",
    "    batch_size=10,\n",
    "    images_per_file=50,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing a likelihood Matrix\n",
    "\n",
    "Now we have a heterogeneous dataset. Let's say we have a new ensemble (I'll use the true one for simplicity), we want to generate the likelihood between each member of the ensemble and each image. This will give us a likelihood matrix, which can be used for ensemble reweighting among other things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a dataloader\n",
    "\n",
    "Normally, you'll have thousands of images, so loading them all into memory at once is not a good idea. CryoJAX is very flexible, and allows us to use external dataloaders. Here I will use the dataloader implemented in: https://github.com/BirkhoffG/jax-dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jax_dataloader (run this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax_dataloader as jdl\n",
    "\n",
    "\n",
    "class CustomJaxDataset(jdl.Dataset):\n",
    "    def __init__(self, cryojax_dataset: RelionParticleStackDataset):\n",
    "        self.cryojax_dataset = cryojax_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.cryojax_dataset[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.cryojax_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = jdl.DataLoader(\n",
    "    CustomJaxDataset(\n",
    "        particle_dataset\n",
    "    ),  # Can be a jdl.Dataset or pytorch or huggingface or tensorflow dataset\n",
    "    backend=\"jax\",  # Use 'jax' backend for loading data\n",
    "    batch_size=20,  # Batch size\n",
    "    shuffle=False,  # Shuffle the dataloader every iteration or not\n",
    "    drop_last=False,  # Drop the last batch or not\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the likelihood\n",
    "\n",
    "Here we show several ways to compute the likelihood. I will show how to compute it using vmapping, but also jax.lax.map, which is usually more memory friendly. I will also show how to compute the likelihood from a stack of atom_positions, which will be useful for computing gradients for atomic structures.\n",
    "\n",
    "In all cases we will vmap first over images and then over structures/potentials. This is because computing quantities this way is faster. Think about it this way, it is much more easier to grab one potential and compute all the images required, than to compute a potential for every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(None, eqx.if_array(0), None))\n",
    "def compute_likelihood(\n",
    "    potential_id: int,\n",
    "    particle_stack,\n",
    "    args: Tuple[\n",
    "        Tuple[cxs.AbstractPotentialRepresentation], cxs.AbstractPotentialIntegrator\n",
    "    ],\n",
    ") -> Float:\n",
    "    potentials, potential_integrator = args\n",
    "    structural_ensemble = cxs.DiscreteStructuralEnsemble(\n",
    "        potentials,\n",
    "        particle_stack[\"parameters\"][\"pose\"],\n",
    "        cxs.DiscreteConformationalVariable(potential_id),\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        potential_integrator,\n",
    "        particle_stack[\"parameters\"][\"transfer_theory\"],\n",
    "    )\n",
    "    image_model = cxs.ContrastImageModel(\n",
    "        particle_stack[\"parameters\"][\"instrument_config\"], scattering_theory\n",
    "    )\n",
    "\n",
    "    simulated_image = image_model.render()\n",
    "    observed_image = particle_stack[\"images\"]\n",
    "\n",
    "    # This is to estimate the snr\n",
    "    cc = jnp.mean(simulated_image**2)\n",
    "    co = jnp.mean(observed_image * simulated_image)\n",
    "    c = jnp.mean(simulated_image)\n",
    "    o = jnp.mean(observed_image)\n",
    "\n",
    "    scale = (co - c * o) / (cc - c**2)\n",
    "    bias = o - scale * c\n",
    "\n",
    "    # remember the noise variance is 1!!\n",
    "    return -jnp.sum((observed_image - scale * simulated_image - bias) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing with equinox.filter_vmap\n",
    "\n",
    "This is the simplest way to compute the likelihood matrix. Simply set a batch_size in the dataloader such that you don't get memory errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(0, None, None))\n",
    "def compute_likelihood_batch(\n",
    "    potential_id: int,\n",
    "    relion_particle_stack,\n",
    "    args: Tuple[\n",
    "        Tuple[cxs.AbstractPotentialRepresentation], cxs.AbstractPotentialIntegrator\n",
    "    ],\n",
    "):\n",
    "    return compute_likelihood(potential_id, relion_particle_stack, args)\n",
    "\n",
    "\n",
    "def compute_likelihood_matrix(\n",
    "    dataloader: jdl.DataLoader,\n",
    "    args: Tuple[cxs.AbstractPotentialRepresentation, cxs.AbstractPotentialIntegrator],\n",
    ") -> Float[Array, \" n_images n_potentials\"]:\n",
    "    n_potentials = len(args[0])\n",
    "    likelihood_matrix = []\n",
    "    for batch in dataloader:\n",
    "        batch_likelihood = compute_likelihood_batch(\n",
    "            jnp.arange(n_potentials), batch, args\n",
    "        ).T\n",
    "        likelihood_matrix.append(batch_likelihood)\n",
    "    likelihood_matrix = jnp.concatenate(likelihood_matrix, axis=0)\n",
    "    return likelihood_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix = compute_likelihood_matrix(\n",
    "    dataloader, args=(potentials, potential_integrator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population for id 0: 30\n",
      "Population for id 1: 70\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the populations by checking which structure\n",
    "# obtains the highest likelihood for each image\n",
    "# They should be around 0.3 and 0.7 (this will not be true at low SNR)\n",
    "\n",
    "print(f\"Population for id 0: {jnp.sum(jnp.argmax(likelihood_matrix, axis=1) == 0)}\")\n",
    "print(f\"Population for id 1: {jnp.sum(jnp.argmax(likelihood_matrix, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing with jax.lax.map\n",
    "\n",
    "Here we need to use equinox partition, as jax.lax.map does not have utilities such as eqx.if_array (see how we vmapped in the previous example). The filtering is very simple, we just need to get rid of all leaves that are not arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def compute_single_likelihood(\n",
    "    potential_id: int,\n",
    "    particle_stack,\n",
    "    args: Tuple[\n",
    "        Tuple[cxs.AbstractPotentialRepresentation], cxs.AbstractPotentialIntegrator\n",
    "    ],\n",
    ") -> Float:\n",
    "    potentials, potential_integrator = args\n",
    "    structural_ensemble = cxs.DiscreteStructuralEnsemble(\n",
    "        potentials,\n",
    "        particle_stack[\"parameters\"][\"pose\"],\n",
    "        cxs.DiscreteConformationalVariable(potential_id),\n",
    "    )\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        potential_integrator,\n",
    "        particle_stack[\"parameters\"][\"transfer_theory\"],\n",
    "    )\n",
    "    image_model = cxs.ContrastImageModel(\n",
    "        particle_stack[\"parameters\"][\"instrument_config\"], scattering_theory\n",
    "    )\n",
    "\n",
    "    simulated_image = image_model.render()\n",
    "    observed_image = particle_stack[\"images\"]\n",
    "\n",
    "    # This is to estimate the snr\n",
    "    cc = jnp.mean(simulated_image**2)\n",
    "    co = jnp.mean(observed_image * simulated_image)\n",
    "    c = jnp.mean(simulated_image)\n",
    "    o = jnp.mean(observed_image)\n",
    "\n",
    "    scale = (co - c * o) / (cc - c**2)\n",
    "    bias = o - scale * c\n",
    "\n",
    "    # remember the noise variance is 1!!\n",
    "    return -jnp.sum((observed_image - scale * simulated_image - bias) ** 2) / 2.0\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def compute_likelihood_with_map(\n",
    "    potential_id: int,\n",
    "    particle_stack,\n",
    "    args: Tuple[\n",
    "        Tuple[cxs.AbstractPotentialRepresentation], cxs.AbstractPotentialIntegrator\n",
    "    ],\n",
    "    *,\n",
    "    batch_size_images: int,\n",
    ") -> Float[Array, \" n_structures\"]:\n",
    "    \"\"\"\n",
    "    Computes one row of the likelihood matrix (all structures, one image)\n",
    "    \"\"\"\n",
    "\n",
    "    stack_map, stack_nomap = eqx.partition(particle_stack, eqx.is_array)\n",
    "\n",
    "    likelihood_batch = jax.lax.map(\n",
    "        lambda x: compute_single_likelihood(\n",
    "            potential_id, eqx.combine(x, stack_nomap), args\n",
    "        ),\n",
    "        xs=stack_map,\n",
    "        batch_size=batch_size_images,  # compute for this many images in parallel\n",
    "    )\n",
    "    return likelihood_batch\n",
    "\n",
    "\n",
    "def compute_likelihood_matrix_with_lax_map(\n",
    "    dataloader: jdl.DataLoader,\n",
    "    args: Tuple[\n",
    "        Tuple[cxs.AbstractPotentialRepresentation], cxs.AbstractPotentialIntegrator\n",
    "    ],\n",
    "    *,\n",
    "    batch_size_potentials: int = None,\n",
    "    batch_size_images: int = None,\n",
    ") -> Float[Array, \" n_images n_structures\"]:\n",
    "    n_potentials = len(args[0])\n",
    "    likelihood_matrix = []\n",
    "    for batch in dataloader:\n",
    "        batch_likelihood = jax.lax.map(\n",
    "            lambda x: compute_likelihood_with_map(\n",
    "                x, batch, args, batch_size_images=batch_size_images\n",
    "            ),\n",
    "            xs=jnp.arange(n_potentials),\n",
    "            batch_size=batch_size_potentials,  # potentials to compute in parallel\n",
    "        ).T\n",
    "        likelihood_matrix.append(batch_likelihood)\n",
    "    likelihood_matrix = jnp.concatenate(likelihood_matrix, axis=0)\n",
    "    return likelihood_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take longer, but uses less memory. Play around with the batch sizes. `batch_size_potentials` controls how many potentials are used in a single vmap operation. `batch_size_images` controls how many images are used in a single vmap operation. Atomic potentials are cheap when it comes to memory, but they are slower when comparing against many images. Voxel potentials are more memory expensive, but it's vary fast to compare them against many images. This might not be true if you need to compute gradients. Always profile your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_matrix_lax_map = compute_likelihood_matrix_with_lax_map(\n",
    "    dataloader,\n",
    "    args=(potentials, potential_integrator),\n",
    "    batch_size_potentials=3,\n",
    "    batch_size_images=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We get the same result as before\n",
    "jnp.allclose(likelihood_matrix_lax_map, likelihood_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing likelihood matrix from multiple atomic positions\n",
    "\n",
    "Here we will not convert the atomic potential to a voxel potential, as the objective of this tutorial is to be able to create a loss function that allows for the computation of gradients for the atomic positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(None, eqx.if_array(0)))\n",
    "def compute_likelihood_atomic(\n",
    "    potential: cxs.AbstractAtomicPotential, particle_stack\n",
    ") -> Float:\n",
    "    structural_ensemble = cxs.SingleStructureEnsemble(\n",
    "        potential,\n",
    "        particle_stack[\"parameters\"][\"pose\"],\n",
    "    )\n",
    "    potential_integrator = cxs.GaussianMixtureProjection()\n",
    "\n",
    "    scattering_theory = cxs.WeakPhaseScatteringTheory(\n",
    "        structural_ensemble,\n",
    "        potential_integrator,\n",
    "        particle_stack[\"parameters\"][\"transfer_theory\"],\n",
    "    )\n",
    "    image_model = cxs.ContrastImageModel(\n",
    "        particle_stack[\"parameters\"][\"instrument_config\"], scattering_theory\n",
    "    )\n",
    "\n",
    "    simulated_image = image_model.render()\n",
    "    observed_image = particle_stack[\"images\"]\n",
    "\n",
    "    # This is to estimate the snr\n",
    "    cc = jnp.mean(simulated_image**2)\n",
    "    co = jnp.mean(observed_image * simulated_image)\n",
    "    c = jnp.mean(simulated_image)\n",
    "    o = jnp.mean(observed_image)\n",
    "\n",
    "    scale = (co - c * o) / (cc - c**2)\n",
    "    bias = o - scale * c\n",
    "\n",
    "    # remember the noise variance is 1!!\n",
    "    return -jnp.sum((observed_image - scale * simulated_image - bias) ** 2) / 2.0\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "@partial(eqx.filter_vmap, in_axes=(0, None, None))\n",
    "def compute_likelihood_build_potential(\n",
    "    atom_positions: Float[Array, \" n_atoms 3\"],\n",
    "    particle_stack,\n",
    "    args: Tuple[\n",
    "        Float[Array, \" n_atoms\"],\n",
    "        dict[str, Float[Array, \" n_atoms n_gaussians\"]],\n",
    "    ],\n",
    "):\n",
    "    b_factors, parameter_table = args\n",
    "    atom_potential = cxs.PengAtomicPotential(\n",
    "        atom_positions,\n",
    "        scattering_factor_a=parameter_table[\"a\"],\n",
    "        scattering_factor_b=parameter_table[\"b\"],\n",
    "        b_factors=b_factors,\n",
    "    )\n",
    "    return compute_likelihood_atomic(atom_potential, particle_stack)\n",
    "\n",
    "\n",
    "def compute_likelihood_matrix_from_atoms(\n",
    "    batch_atom_positions: Float[Array, \" n_structures n_atoms 3\"],\n",
    "    dataloader: jdl.DataLoader,\n",
    "    args: Tuple[\n",
    "        Float[Array, \" n_atoms\"],\n",
    "        dict[str, Float[Array, \" n_atoms n_gaussians\"]],\n",
    "    ],\n",
    ") -> Float[Array, \" n_images n_structures\"]:\n",
    "    likelihood_matrix = []\n",
    "    for batch in dataloader:\n",
    "        batch_likelihood = compute_likelihood_build_potential(\n",
    "            batch_atom_positions, batch, args\n",
    "        ).T  # we want something with shape (n_images, n_atom_positions)\n",
    "\n",
    "        likelihood_matrix.append(batch_likelihood)\n",
    "    likelihood_matrix = jnp.concatenate(likelihood_matrix, axis=0)\n",
    "    return likelihood_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WARNING\n",
    "Here I am assuming that all atomic structures have the same set of atoms. Generalizing is not difficult, you just need to be careful about how you handle the atom_identities and the b_factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "filenames = [\"./data/groel_chainA.pdb\", \"./data/groel_chainA_holo.pdb\"]\n",
    "\n",
    "box_size = instrument_config.shape[0]\n",
    "voxel_size = instrument_config.pixel_size\n",
    "\n",
    "single_atom_positions, atom_identities, b_factors = read_atoms_from_pdb(\n",
    "    filenames[0], center=True, select=\"not element H\", loads_b_factors=True\n",
    ")\n",
    "\n",
    "# This is needed to define the Peng Atomic Potential\n",
    "parameter_table = get_tabulated_scattering_factor_parameters(atom_identities)\n",
    "\n",
    "batch_atom_positions = np.zeros((len(filenames), *single_atom_positions.shape))\n",
    "batch_atom_positions[0] = single_atom_positions\n",
    "\n",
    "for i, filename in enumerate(filenames[1:]):\n",
    "    # Load the atomic structure and transform into a potential\n",
    "    batch_atom_positions[i + 1] = read_atoms_from_pdb(\n",
    "        filename, center=True, select=\"not element H\", loads_b_factors=False\n",
    "    )[0]  # we are only interested in the positions, the resto does not change\n",
    "\n",
    "batch_atom_positions = jnp.array(batch_atom_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (b_factors, parameter_table)\n",
    "\n",
    "likelihood_matrix_atoms = compute_likelihood_matrix_from_atoms(\n",
    "    batch_atom_positions, dataloader, args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population for id 0: 30\n",
      "Population for id 1: 70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Population for id 0: {jnp.sum(jnp.argmax(likelihood_matrix_atoms, axis=1) == 0)}\")\n",
    "print(f\"Population for id 1: {jnp.sum(jnp.argmax(likelihood_matrix_atoms, axis=1) == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryojax_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
